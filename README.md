
#  Day 0 of AI / ML â€” Foundations Only

### Goal of Day 0

-Build **mental clarity + basic tools**, not intelligence
-No math, no models, no pressure

---

## 1>>> What AI / ML Actually Is (Conceptual)

You should clearly understand this sentence:

> **Machine Learning = teaching a computer to learn patterns from data instead of writing rules**

### Learn the difference:

* **AI** â†’ Big umbrella (smart behavior)
* **ML** â†’ Learning from data
* **DL** â†’ Neural networks (later)

 Day 0 rule:
If you can explain this to a non-tech person â†’ youâ€™re ready.

---

## 2>>>> Python Basics (Only These)

You **DO NOT** learn full Python today.

Learn ONLY:

* Variables 
* Data types (`int, float, str, bool`)
* `print()`
* Comments (`#`)
* Simple input/output

Example:

```python
name = "AI from 0"
day = 0
print(name, day)
```

- If you understand this â†’ enough for Day 0.

---

## 3>>>> How Code Thinks (VERY IMPORTANT)

Learn **how a computer thinks**:

* Top to bottom
* Line by line
* No emotions, no guessing
Example:

```python
x = 5
x = x + 2
print(x)
```

Output is `7` because computer follows steps **literally**.

This mindset matters more than syntax.

---

## 4ï¸>>>> Basic Command Line Awareness (Light)

Just know:

* What a **terminal** is
* What `python file.py` means
* What an error message looks like

No Linux mastery. Just awareness.

---

## 5>>> Git & GitHub (Observer Level)

For Day 0, only understand:

* GitHub = place to store code
* Repo = project folder
* README = explanation file

You **do not** need commands yet.

---

## 6ï¸>>> Math? -- NOT TODAY

No:

* Linear algebra
* Calculus
* Probability

 Day 0 is about **confidence**, not intelligence.

---

## 7ï¸>>>> Mindset for AI (Most Important)

You must accept:

* AI is **slow learning**
* Confusion is normal
* Consistency beats talent
* You will re-learn the same thing multiple times

This is not a sprint.

---

## ---- Day 0 Checklist (If all true â†’ youâ€™re done)

âœ” I know what AI / ML means
âœ” I can write basic Python variables
âœ” I understand code runs line by line
âœ” Iâ€™m not scared of errors
âœ” Iâ€™m excited, not overwhelmed

If yes â†’ **Day 0 completed **

---

##  What Comes on Day 1 (Preview)

* Python data types (deep)
* Lists & loops
* First tiny â€œlearning logicâ€
* Thinking like a machine

---










#  Day 1 of AI / ML (Python + Thinking)

###  Goal of Day 1

By the end of today, you should:

* Think **logically like a machine**
* Be comfortable with **core Python**
* Be ready to handle **data (very small data)**

No AI models yet. This is **foundation day**.

---

## Time Plan (2â€“3 hours total)

### 1ï¸>> Data Types (40 min)

You already met them. Now understand them.

| Type    | Example | Use in AI      |
| ------- | ------- | -------------- |
| `int`   | `10`    | counts, epochs |
| `float` | `0.01`  | learning rate  |
| `str`   | `"cat"` | labels, text   |
| `bool`  | `True`  | conditions     |

```python
x = 10
y = 2.5
name = "AI"
is_ai_fun = True

print(type(x), type(y), type(name), type(is_ai_fun))
```

---

### 2ï¸>> Input & Output (20 min)

Make programs interactive.

```python
name = input("Enter your name: ")
print("Welcome to AI,", name)
```

Understand:

* `input()` always gives **string**
* Convert when needed

```python
age = int(input("Enter age: "))
```

---

### 3>> Operators (30 min)

These are **thinking tools**.

#### Arithmetic

```python
+  -  *  /  //  %  **
```

#### Comparison (VERY IMPORTANT)

```python
>  <  >=  <=  ==  !=
```

Example:

```python
x = 10
print(x > 5)   # True
```

---

### 4>> Conditions (Ifâ€“Else) (40 min)

This is where **decision-making** starts.

```python
marks = 75

if marks >= 40:
    print("Pass")
else:
    print("Fail")
```

AI = lots of **conditions + data**.

---

### >> Lists (Core of ML Data) (40 min)

Lists store **multiple values**.

```python
marks = [60, 70, 80, 90]
print(marks[0])
```

Why lists matter:

* Datasets = lists
* Features = lists
* Outputs = lists

```python
numbers = [1, 2, 3]
numbers.append(4)
print(numbers)
```

---

### >> Loops (Machine Repetition) (30 min)

Machines are good at repetition.

```python
for i in range(5):
    print(i)
```

Loop through data:

```python
marks = [60, 70, 80]

for m in marks:
    print(m)
```

AI training = loops + updates.

---

##  Mini Practice (MANDATORY)

Do these without copy-paste:

> Take 5 numbers from user, store in list
> Print all numbers
> Print numbers greater than 50

Example logic:

```python
numbers = []

for i in range(5):
    num = int(input("Enter number: "))
    numbers.append(num)

for n in numbers:
    if n > 50:
        print(n)
```

---



##  Mindset Check

* Confusion = progress
* Errors = learning
* Repetition = mastery

---

##  Day 2 Preview

* Functions
* Tuples & dictionaries
* Problem-solving like ML
* Tiny â€œlearning logicâ€ program





#  Day 2 â€” Functions, Data Structures & Thinking Like ML

###  Goal of Day 2

By the end of Day 2, a beginner should:

* Write **functions**
* Use **tuples & dictionaries**
* Start thinking in **inputs â†’ processing â†’ outputs**
* Understand how ML code is structured

Still **no models yet** â€” but now youâ€™re coding *like* ML.

---

## 1ï¸. Functions (Core of ML Code)

### What is a Function?

A function is a **reusable block of code** that performs a task.

```python
def greet():
    print("Welcome to AI")
```

Call it:

```python
greet()
```

---

### Function with Parameters

```python
def add(a, b):
    return a + b

result = add(5, 3)
print(result)
```

Why functions matter in ML:

* training step
* prediction step
* evaluation step

All are functions.

---

## 2ï¸. Return vs Print (IMPORTANT)

```python
def square(x):
    return x * x
```

 `return` gives value back
 `print` only displays

ML functions **always return values**.

---

## 3ï¸. Tuples (Fixed Data)

Tuples are **immutable** (cannot be changed).

```python
point = (3, 5)
x, y = point
```

Used for:

* coordinates
* dataset rows
* fixed configs

---

## 4ï¸. Dictionaries (KEY ML STRUCTURE)

### What is a Dictionary?

Stores data as **key : value pairs**.

```python
student = {
    "name": "Prabha",
    "age": 17,
    "field": "AI"
}
```

Access:

```python
print(student["name"])
```

Why dictionaries matter in ML:

* model parameters
* datasets
* configs
* metrics

Example:

```python
metrics = {
    "loss": 0.23,
    "accuracy": 92.5
}
```

---

## 5ï¸. Looping Through Dictionaries

```python
for key, value in metrics.items():
    print(key, value)
```

This is **very common** in training logs.

---

## 6. Simple ML-Style Logic (IMPORTANT)

### Example: Mean (Average)

```python
def mean(numbers):
    total = 0
    for n in numbers:
        total += n
    return total / len(numbers)

data = [10, 20, 30, 40]
print(mean(data))
```

This is **literally how ML starts**.

---

## 7ï¸. Input â†’ Process â†’ Output (ML Thinking)

```python
def classify(score):
    if score >= 50:
        return "Pass"
    return "Fail"
```

ML is just **complex versions of this**.

---

##  Practice (Mandatory)

> Write a function to find max in a list
> Store student info in dictionary
> Loop through dictionary and print neatly

Example:

```python
def find_max(nums):
    m = nums[0]
    for n in nums:
        if n > m:
            m = n
    return m
```

---



##  Day 2 Mindset

* Functions = ML blocks
* Dictionaries = ML memory
* Loops = training
* Logic = intelligence

---

##  Day 3 Preview

* Lists (deep)
* Nested loops
* Data preprocessing mindset
* First tiny â€œlearningâ€ system




# Day 3 â€” Lists, Loops & Simple Data Handling

## Goal

* Work comfortably with lists
* Use loops to process data
* Think step-by-step

---

## Lists (Deep Basics)

```python
numbers = [10, 20, 30, 40]
```

Access:

```python
numbers[0]
numbers[-1]
```

Modify:

```python
numbers.append(50)
numbers.remove(20)
```

---

## Looping Through Lists

```python
for n in numbers:
    print(n)
```

With index:

```python
for i in range(len(numbers)):
    print(i, numbers[i])
```

---

## Nested Lists

```python
matrix = [
    [1, 2],
    [3, 4]
]
```

Loop:

```python
for row in matrix:
    for value in row:
        print(value)
```

---

## Simple Data Processing

Sum:

```python
total = 0
for n in numbers:
    total += n
```

Filter:

```python
for n in numbers:
    if n > 25:
        print(n)
```

---

## Practice

1. Take 5 numbers from user
2. Store in list
3. Print max and average

---




# Day 4 â€” Strings, Files & Basic Data Cleaning

## Goal

* Work with text (strings)
* Read/write files
* Clean simple data

---

## Strings

```python
text = "AI from zero"
```

Basic operations:

```python
text.lower()
text.upper()
text.strip()
text.replace("zero", "0")
```

Split & join:

```python
words = text.split()
joined = " ".join(words)
```

---

## Looping Through Strings

```python
for ch in text:
    print(ch)
```

---

## Files (Read)

```python
file = open("data.txt", "r")
content = file.read()
file.close()
```

Line by line:

```python
for line in open("data.txt"):
    print(line.strip())
```

---

## Files (Write)

```python
file = open("output.txt", "w")
file.write("Hello World")
file.close()
```

---

## Basic Data Cleaning

Remove spaces:

```python
name = "  Prabha  "
clean = name.strip()
```

Lowercase + split:

```python
sentence = "Python Is Fun"
words = sentence.lower().split()
```

Remove empty values:

```python
data = ["10", "", "20", " ", "30"]
cleaned = [x for x in data if x.strip() != ""]
```

---

## Practice

1. Read a file
2. Convert text to lowercase
3. Remove empty lines
4. Save cleaned text to new file

---



# Day 5 â€” Data Handling & Simple Learning Logic

## Goal

* Work with numerical data
* Process data step by step
* Understand what â€œlearningâ€ means

---

## Working with Data

```python
data = [10, 20, 30, 40, 50]
```

Basic operations:

```python
min(data)
max(data)
sum(data)
len(data)
```

---

## Simple Feature Processing

```python
scaled = []
for x in data:
    scaled.append(x / max(data))
```

---

## Simple Rule-Based Prediction

```python
def predict(x):
    if x > 0.5:
        return 1
    return 0
```

---

## Measuring Performance

```python
y_true = [1, 0, 1, 1]
y_pred = [1, 0, 0, 1]

correct = 0
for i in range(len(y_true)):
    if y_true[i] == y_pred[i]:
        correct += 1

accuracy = correct / len(y_true)
print(accuracy)
```

---

## Core Idea

Learning =
data â†’ rules â†’ evaluation â†’ improvement

---

## Practice

1. Normalize a list of numbers
2. Write a simple prediction rule
3. Calculate accuracy manually

---


## Next

* **Day 6**: Introduction to NumPy & arrays



### **Day 6 â€“ NumPy & Arrays **

This is **core AI/ML groundwork**. Donâ€™t rush this day.

---

## 1ï¸. Array Data Types

```python
arr = np.array([1, 2, 3], dtype=float)
```

Common types:

* `int`
* `float`
* `bool`

Why it matters: ML math **breaks** with wrong dtypes.

---

## 2ï¸. Type Conversion

```python
arr = np.array([1, 2, 3])
arr = arr.astype(float)
```

---

## 3ï¸. Reshaping Arrays (VERY IMPORTANT)

```python
arr = np.array([1, 2, 3, 4, 5, 6])

arr.reshape(2, 3)
```

Used in:

* datasets
* neural network inputs

---

## 4ï¸. Flattening

```python
matrix = np.array([[1, 2], [3, 4]])

matrix.flatten()
```

---

## 5ï¸. Array Copy vs View (Critical Concept)

```python
a = np.array([1, 2, 3])
b = a.copy()

b[0] = 100
```

`copy()` â†’ independent
without copy â†’ linked (danger in ML)

---

## 6ï¸. Boolean Indexing

```python
arr = np.array([10, 20, 30, 40])

arr[arr > 20]
```

Used for:

* data filtering
* cleaning datasets

---

## 7ï¸. Random Arrays

```python
np.random.rand(5)
np.random.randint(1, 10, size=5)
```

Used in:

* weight initialization
* simulations

---

## 8ï¸. Basic Statistics

```python
arr = np.array([1, 2, 3, 4])

arr.mean()
arr.max()
arr.min()
arr.sum()
```

---

## 9ï¸. Broadcasting (ML Magic)

```python
arr = np.array([1, 2, 3])

arr + np.array([10])
```

No loops. Fast. Clean.

---

## What You Should NOT Learn Yet 

* Pandas
* SciPy
* TensorFlow
* PyTorch

---


## to explore more features of numpy, go to my numpy.py file




### **Day 7 â€“ Conditional Logic for AI/ML**


## What You Learn (Day 7)

### 1ï¸. Conditional Statements (Core)

```python
if x > 0:
    print("Positive")
elif x == 0:
    print("Zero")
else:
    print("Negative")
```

Used for:

* decision making
* data filtering
* rule-based logic

---

### 2ï¸. Conditions with NumPy Arrays

```python
import numpy as np

arr = np.array([10, 20, 30, 40])
arr[arr > 25]
```

This is **real ML-style filtering**.

---

### 3ï¸. Boolean Masks

```python
mask = arr % 2 == 0
arr[mask]
```

Used in:

* cleaning data
* removing outliers

---

### 4ï¸. `np.where()` (Very Important)

```python
np.where(arr > 25, 1, 0)
```

Used in:

* labeling data
* feature engineering

---

---

### Why Day 7 Matters

* ML models learn from **conditions**
* Labels = conditional logic
* Data preprocessing starts here

---


### **Day 8 â€“ Functions for AI/ML (Clean & Practical)**

Day 8 is about turning logic into **reusable, testable units** â€” exactly how ML pipelines work.

---

## What You Learn (Day 8)

### 1ï¸. Defining Functions

```python
def add(a, b):
    return a + b
```

Used in:

* data processing
* feature engineering
* model steps

---

### 2ï¸. Parameters & Return Values

```python
def normalize(x):
    return (x - min(x)) / (max(x) - min(x))
```

---

### 3ï¸. Default Arguments

```python
def train_model(epochs=10):
    print(epochs)
```

---

### 4ï¸. Functions with NumPy Arrays

```python
import numpy as np

def mean_value(arr):
    return np.mean(arr)
```

Core ML pattern.

---

### 5ï¸. Multiple Return Values

```python
def stats(arr):
    return arr.mean(), arr.std()
```

---

### 6ï¸. Function Composition

```python
def square(x):
    return x*x

def cube(x):
    return square(x) * x
```

---



## Why Day 8 Matters for AI/ML

* ML code = chained functions
* Clean experiments
* Reproducibility

---





## What NOT to Learn Yet 

* decorators
* closures
* recursion (for now)

---


### DAY 9 of AI/ML
###  Topic: **Overfitting & Underfitting + Model Evaluation**

#### 1ï¸>>> Underfitting

* Model is **too simple**
* Canâ€™t capture patterns in data
* **High bias**
* Poor performance on **both training & test data**

**Example:**
Using a straight line to fit curved data.

---

#### 2ï¸>>> Overfitting

* Model is **too complex**
* Learns noise instead of pattern
* **High variance**
* Very good on training data but bad on test data

**Example:**
A model that memorizes every training point.

---

#### 3ï¸>>> Perfect Fit (What we want)

* Balanced complexity
* Learns patterns, not noise
* Good performance on **unseen data**

---

###  How to Detect Them

| Situation    | Training Error | Test Error |
| ------------ | -------------- | ---------- |
| Underfitting | High           | High       |
| Overfitting  | Low            | High       |
| Good Model   | Low            | Low        |

---

###  Ways to Fix

**Fix Underfitting**

* Use more complex model
* Add more features
* Train longer

**Fix Overfitting**

* Get more data
* Feature selection
* Regularization (L1/L2)
* Dropout (in neural networks)

---

###  Model Evaluation Metrics

* **Accuracy** â€“ overall correctness
* **Precision** â€“ how many predicted positives were correct
* **Recall** â€“ how many actual positives were found
* **F1-score** â€“ balance of precision & recall

---

###  Mini Task (Do this today)

1. Write definitions of:

   * Overfitting
   * Underfitting
2. Answer:
   *If training accuracy = 98% and test accuracy = 65%, what is happening and why?*
Alright, **Day 10 of AI & ML** 
Letâ€™s level up.

---

## **Day 10: Model Evaluation & Performance Metrics**

Yesterday you learned how models are trained.
Today, youâ€™ll learn **how to judge whether your model is actually good or just pretending**.

---

## **1. Why Model Evaluation Matters**

Training accuracy alone is **misleading**.
A model can:

* Memorize data (overfitting)
* Perform well on training data but fail on new data

 Evaluation tells us **how well the model generalizes**.

---

## **2. Train vs Test Data**

We split data into:

* **Training set** â†’ model learns from this
* **Testing set** â†’ model is evaluated on unseen data

Typical split:

* 80% training
* 20% testing

---

## **3. Confusion Matrix (VERY IMPORTANT)**

Used in **classification problems**

| Actual \ Predicted | Positive | Negative |
| ------------------ | -------- | -------- |
| Positive           | TP       | FN       |
| Negative           | FP       | TN       |

* **TP** â†’ True Positive
* **TN** â†’ True Negative
* **FP** â†’ False Positive
* **FN** â†’ False Negative

---

## **4. Key Evaluation Metrics**

###  Accuracy

```
Accuracy = (TP + TN) / Total
```

Good when data is **balanced**

---

###  Precision

```
Precision = TP / (TP + FP)
```

 â€œWhen model says YES, how often is it correct?â€

---

###  Recall

```
Recall = TP / (TP + FN)
```

 â€œOut of actual YES cases, how many did we catch?â€

---

###  F1 Score

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

Best when:

* Data is imbalanced
* Precision & Recall both matter

---

## **5. When to Use What**

* **Accuracy** â†’ balanced dataset
* **Precision** â†’ spam detection, fake news
* **Recall** â†’ disease detection, fraud detection
* **F1 Score** â†’ overall performance

---

## **6. Overfitting vs Underfitting**

* **Overfitting** â†’ high train accuracy, low test accuracy
* **Underfitting** â†’ low accuracy everywhere

Goal: **balance**

---

## **7. Mini Python Example (conceptual)**

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy_score(y_test, y_pred)
precision_score(y_test, y_pred)
recall_score(y_test, y_pred)
f1_score(y_test, y_pred)
```

---

## **Your Task (Must Do) **

1. Write definitions for:

   * Accuracy
   * Precision
   * Recall
   * F1 Score
2. Answer:

   > Why is accuracy not enough for imbalanced datasets?

---

### Tomorrow (Day 11 ðŸ‘€)

**Biasâ€“Variance Tradeoff + Cross Validation**
This is where ML starts feeling *real*.


# Day 11 â€” Biasâ€“Variance Tradeoff + Cross Validation

## Biasâ€“Variance Tradeoff (Practical View)

In ML, model error comes from two opposite problems:

### High Bias â†’ Underfitting

Model is too simple â†’ misses real patterns.

**Signs**

* Bad training performance
* Bad validation performance
* Model too rigid

**Example**

```text
Linear model trying to fit curved data
```

---

### High Variance â†’ Overfitting

Model is too complex â†’ learns noise.

**Signs**

* Very good training score
* Poor validation score
* Model too sensitive to data

**Example**

```text
Deep tree memorizing training set
```

---

### Tradeoff Goal

Find model complexity where validation error is lowest.

```
Too simple â†’ High bias
Too complex â†’ High variance
Balanced â†’ Best generalization
```

---

## Error vs Complexity Curve (Concept)

```
Complexity increases
Bias decreases
Variance increases
Total Error forms a U-shaped curve
```

We aim for the bottom of the U.

---

# Cross Validation (How we measure it properly)

Instead of one train/test split, we test model multiple times on different splits.

Why?
Because single split results can be misleading.

---

## k-Fold Cross Validation

### Steps

```
Split data into k parts
Repeat k times:
    Train on k-1 folds
    Validate on remaining fold
Average the scores
```

---

## Example (Python)

```python
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression

model = LinearRegression()
scores = cross_val_score(model, X, y, cv=5)

print(scores)
print("Mean accuracy:", scores.mean())
```

---

## Why This Matters

Cross validation helps:

```
detect overfitting
compare models fairly
choose hyperparameters
estimate real performance
```

---

## How It Connects to Biasâ€“Variance

```
High variance model â†’ CV scores unstable
High bias model â†’ CV scores consistently low
Good model â†’ CV scores stable and high
```

---

## Day 11 Takeaway

Good ML is not about best training accuracy â€”
itâ€™s about best validation performance.
